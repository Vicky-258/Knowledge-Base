# ğŸŸ§ WEEK 3 â€” Deep Forecasting (Informer-lite)

**Theme:** Stop reading. Start building.  
**Outcome:** A working LSTM-based workload predictor that forecasts the next 12 steps.

---

## ğŸŸ§ Day 1 â€” Data Pipeline & Framing the Problem

### ğŸ¯ Goal:
Turn raw metrics into a supervised learning problem.

### âœ… Tasks:
- [x] Choose **one metric** as workload signal (CPU or RPS)
- [x] Load historical data (from Week 2 scrape)
- [x] Normalize the series (MinMax / StandardScaler)
- [x] Decide:
  - [x] input window size (e.g. 24 or 60)
  - [x] prediction horizon = 12
- [x] Implement sliding window dataset:
  - X â†’ past `window_size`
  - y â†’ next `12` values
- [x] Plot:
  - raw series
  - one sample window â†’ target

ğŸ“Œ **Checkpoint:**  
You can clearly explain:  
â€œGiven the past ___ points, I predict the next 12.â€

---

## ğŸŸ§ Day 2 â€” LSTM Model (Single-Step First)

### ğŸ¯ Goal:
Get a **minimal LSTM** to learn *anything*.

### âœ… Tasks:
- [x] Implement basic LSTM model:
  - input â†’ LSTM â†’ Linear
- [x] Start with **single-step prediction**
- [x] Choose loss:
  - [x] MSE
- [x] Train for a few epochs
- [x] Plot:
  - predicted vs actual (1-step)

ğŸ“Œ **Rule:**  
No fancy tricks. If this doesnâ€™t learn, stop and debug.

ğŸ“Œ **Checkpoint:**  
Loss goes down. Predictions are not random noise.

---

## ğŸŸ§ Day 3 â€” Multi-Step Forecasting (Next 12 Steps)

### ğŸ¯ Goal:
Predict **12 future steps at once**.

### âœ… Tasks:
- [x] Modify model output â†’ size 12
- [x] Update dataset target accordingly
- [x] Train multi-step LSTM
- [x] Plot:
  - true future vs predicted future (12-step curve)
- [x] Measure:
  - [x] MSE per horizon
  - [x] overall MSE

ğŸ“Œ **Checkpoint:**  
You can visually see trend continuation (even if imperfect).

---

## ğŸŸ§ Day 4 â€” GRU Variant (Comparison Day)

### ğŸ¯ Goal:
Understand *why* GRU sometimes works better.

### âœ… Tasks:
- [x] Replace LSTM with GRU
- [x] Keep everything else identical
- [x] Train GRU model
- [x] Compare:
  - [x] convergence speed
  - [x] stability
  - [x] prediction smoothness
- [x] Write short notes:
  - when GRU felt better
  - when LSTM felt better

ğŸ“Œ **Checkpoint:**  
You understand this is a **design choice**, not dogma.

---

## ğŸŸ§ Day 5 â€” Transformer Encoder (Minimal, Not Fancy)

### ğŸ¯ Goal:
Touch transformers without drowning.

### âœ… Tasks:
- [x] Implement:
  - positional encoding
  - transformer encoder block
- [x] Input shape: (sequence_length, features)
- [x] Output â†’ next 12 steps
- [x] Train on same dataset
- [x] Plot predictions

ğŸ“Œ **Rule:**  
No Informer. No attention hacks.  
Just encoder â†’ linear head.

ğŸ“Œ **Checkpoint:**  
You *understand* what attention is doing, even if performance is similar.

---

## ğŸŸ§ Day 6 â€” Evaluation & Failure Analysis

### ğŸ¯ Goal:
Stop celebrating. Start judging.

### âœ… Tasks:
- [x] Compare:
  - AR (Week 1)
  - LSTM
  - GRU
  - Transformer
- [x] Metrics:
  - [x] MSE
  - [x] MAE
- [x] Test on:
  - smooth workload
  - bursty workload
- [x] Identify:
  - where each model fails
  - lag vs overshoot behavior

ğŸ“Œ **Checkpoint:**  
You can justify *why* one model is chosen for Autoscale.

---

## ğŸŸ§ Day 7 â€” Freeze the Predictor (Engineering Day)

### ğŸ¯ Goal:
Prepare this for integration later.

### âœ… Tasks:
- [ ] Choose **one final predictor**
- [ ] Wrap it as a clean Python module:
  - `fit()`
  - `predict_next_12()`
- [ ] Save / load model weights
- [ ] Add inference-only script
- [ ] Write a short `week3_notes.md`:
  - design choices
  - lessons learned
  - mistakes made

ğŸ“Œ **End-of-Week Win:**  
You now have a **production-shaped workload forecaster**.

---

## ğŸ‰ WEEK 3 COMPLETE

You are officially past:
- toy ML
- notebook-only experiments

Next week = **burst detection**, where prediction meets reality.
