# ğŸš€ WEEK 2 â€” Day-by-Day Plan

_(Monitoring: Prometheus + cAdvisor + Metrics)_

---

# **ğŸ“… DAY 1 â€” Prometheus Basics: Your First Time Series**

### ğŸ¯ Goal:

Understand HOW Prometheus thinks and get comfy with its UI.

### ğŸ§  What you learn:

- ~~What is a scrape target~~ [[Prometheus#What is a scrape target|ans]]
    
- ~~Prometheus data model~~ [[Prometheus#Prometheus Data Model|ans]]
    
- ~~Labels~~ [[Prometheus#What are Labels|ans]]
    
- ~~Time series~~ [[Prometheus#Time series]ans]
    
- ~~Why Prometheus PULLS instead of pushes~~ 
    


### ğŸ› ï¸ Tasks:

1. ~~Run Prometheus locally:
    
    ```
    docker run -p 9090:9090 prom/prometheus
    ```
    
2. ~~Open `localhost:9090`
    
3. ~~Try basic queries:
    
    - `up`
        
    - `prometheus_http_requests_total`
        
    - `rate(prometheus_http_requests_total[1m])`
        

### ğŸ‰ End of Day Win:

You can run PromQL like a baby Grafana wizard.

---

# **ğŸ“… DAY 2 â€” cAdvisor: Container Gym Trainer**

### ğŸ¯ Goal:

Understand container-level metrics: CPU, memory, IO, network.

### ğŸ› ï¸ Tasks:

1. ~~Run cAdvisor:~~ 
    
    ```
    docker run \
      --volume=/:/rootfs:ro \
      --volume=/var/run:/var/run:ro \
      --volume=/sys:/sys:ro \
      --volume=/var/lib/docker/:/var/lib/docker:ro \
      --publish=8080:8080 \
      gcr.io/cadvisor/cadvisor
    ```
    
1. ~~Visit `localhost:8080`~~ 
    
2. ~~Explore:
    
    - ~~CPU throttling
        
    - ~~Memory working set
        
    - ~~Filesystem usage
        
    - ~~Network bytes
        
3. ~~In Prometheus:  ~~
    Query:
    
    ~~- `container_cpu_usage_seconds_total`~~
        
    ~~- `container_memory_working_set_bytes`~~
        
    ~~- `rate(container_network_transmit_bytes_total[1m])`~~
        

### ğŸ‰ End of Day Win:

You understand what your containers eat for breakfast (CPU) and how much they sleep (idle time).

---

# **ğŸ“… DAY 3 â€” Build a Micro API With Metrics**

### ğŸ¯ Goal:

Make your own service that exposes real metrics.

### ğŸ› ï¸ Tasks:

Create FastAPI server with:

- ~~Counter
    
- ~~Histogram
    
- ~~`/metrics` endpoint
    

Code (youâ€™ll write it line-by-lineâ€”you prefer that ğŸ˜ but here's the plan):

1. ~~Counter: `demo_requests_total`
    
2. ~~Latency histogram: `demo_request_latency_seconds`
    
3. ~~Add random sleep to simulate real latency
    
4. ~~Expose `/metrics`
    

Run:

```
uvicorn main:app --port 8000
```

### ğŸ‰ End of Day Win:

You made your first â€œself-monitoring API.â€

---

# **ğŸ“… DAY 4 â€” Prometheus Scrapes Your API**

### ğŸ¯ Goal:

Connect your API + cAdvisor â†’ Prometheus.

### ğŸ› ï¸ Tasks:

Edit Prometheus config:

```yaml
scrape_configs:
  - job_name: "python-api"
    static_configs:
      - targets: ["host.docker.internal:8000"]

  - job_name: "cadvisor"
    static_configs:
      - targets: ["host.docker.internal:8080"]
```

Restart Prometheus.

Verify:

- `demo_requests_total`
    
- `rate(demo_requests_total[1m])`
    
- `histogram_quantile(...)`
    

### ğŸ‰ End of Day Win:

Prometheus collects metrics **you** created.

You are officially a â€œmetrics exporter.â€

---

# **ğŸ“… DAY 5 â€” Load Testing + Visualizing CPU & Latency**

### ğŸ¯ Goal:

Make graphs for:

- CPU usage
    
- p95 latency
    
- Request rate (RPS)
    

### ğŸ› ï¸ Tasks:

1. Load-test:
    
    ```
    while true; do curl -s localhost:8000 >/dev/null; done
    ```
    
2. In Prometheus graph tab, inspect:
    

#### ğŸ”¥ CPU:

```
rate(container_cpu_usage_seconds_total[1m])
```

#### ğŸ•’ p95 latency:

```
histogram_quantile(0.95, rate(demo_request_latency_seconds_bucket[5m]))
```

#### âš¡ RPS:

```
rate(demo_requests_total[1m])
```

### ğŸ‰ End of Day Win:

You read CPU, RPS, latency from charts.  
This is literally what Grafana panels show.

---

# **ğŸ“… DAY 6 â€” Build Your â€œMini Grafanaâ€**

### ğŸ¯ Goal:

Plot metrics together using Prometheus graph or a tiny Python plotting script.

### ğŸ› ï¸ Tasks:

- Export metrics using Prometheus HTTP API
    
- Plot using matplotlib
    
- OR use Prometheus â€œgraphâ€ tab like a dashboard
    
- (optional) Use `promlens` to debug PromQL
    

### ğŸ‰ End of Day Win:

You basically created a Grafana-lite.

---

# **ğŸ“… DAY 7 â€” Review + Apply**

### ğŸ¯ Goal:

Wrap the week with deep understanding.

### ğŸ› ï¸ Tasks:

- Review queries you used
    
- Write down top 10 useful PromQL expressions
    
- Note down the difference between:
    
    - Counter
        
    - Gauge
        
    - Histogram
        
- Try to detect: â€œWhen does CPU spike?â€
    

### ğŸ‰ End of Week Win:

You now **understand real-world metrics**.  
You can debug CPU, memory, latency, and RPS like an SRE trainee.
